# üß™ Manuelle Explorative Tests - Impostor Webanwendung

Dieses Dokument beschreibt die manuellen explorativen Tests, die durchgef√ºhrt werden sollten, um die Qualit√§t und Benutzerfreundlichkeit der Impostor-Webanwendung sicherzustellen.

## üìã Testvorbereitung

### Ben√∂tigte Ger√§te/Browser:
- **Mobile Ger√§te**: iOS Safari, Android Chrome
- **Desktop**: Chrome, Firefox, Safari
- **Tablets**: iPad Safari, Android Chrome

### Test-Szenarien:
1. **Einzelger√§t-Tests**: Ein Ger√§t mit mehreren Tabs/Fenstern
2. **Multi-Ger√§t-Tests**: Verschiedene Ger√§te im selben Netzwerk
3. **Cross-Browser-Tests**: Verschiedene Browser auf demselben Ger√§t

## üéÆ Explorative Testbereiche

### 1. UI/UX Testing (Fokus auf Design-Anforderungen)

#### 1.1 Mobile-First Experience
**Ziel**: Sicherstellen, dass die Anwendung auf mobilen Ger√§ten optimal funktioniert

**Tests**:
- [ ] √ñffne Anwendung auf Smartphone
- [ ] Pr√ºfe Lesbarkeit der Texte ohne Zoom
- [ ] Teste Button-Gr√∂√üen und Abst√§nde
- [ ] √úberpr√ºfe One-Hand-Usability
- [ ] Teste in Hoch- und Querformat

**Erwartete Ergebnisse**:
- Alle Elemente ohne Pinch-to-Zoom lesbar
- Buttons mindestens 44px gro√ü f√ºr Touch
- Navigation mit einer Hand m√∂glich
- Kein horizontaler Scroll n√∂tig

#### 1.2 Design-Konsistenz
**Ziel**: √úberpr√ºfen, ob das Design den Spezifikationen entspricht

**Tests**:
- [ ] Pr√ºfe Farbwelt (wei√ü, dunkelgrau, weiche Farben)
- [ ] √úberpr√ºfe Typografie (Inter Font, korrekte Gr√∂√üen)
- [ ] Teste Animationen und √úberg√§nge
- [ ] Kontrolliere visuelle Hierarchie

**Erwartete Ergebnisse**:
- Farben korrespondieren mit Design-Guide
- Schriftgr√∂√üen folgen der Hierarchie (28pt, 22pt, 16pt, etc.)
- Animationen sind sanft und nicht ablenkend
- Wichtige Elemente sind visuell hervorgehoben

### 2. Edge Case Testing

#### 2.1 Netzwerk-St√∂rungen
**Ziel**: Robustheit bei Verbindungsproblemen

**Tests**:
- [ ] Starte Spiel und unterbreche Internetverbindung
- [ ] Tritt bei Raum bei und verliere Verbindung
- [ ] Teste mit langsamer Verbindung (3G-Simulation)
- [ ] Wechsel zwischen Wi-Fi und Mobile Data

**Erwartete Ergebnisse**:
- Anwendung friert nicht ein
- Informative Fehlermeldungen
- M√∂glichkeit zum Neuladen/Rejoin
- Kein Datenverlust bei Reconnect

#### 2.2 Browser-Kompatibilit√§t
**Ziel**: Funktion √ºber verschiedene Browser hinweg

**Tests**:
- [ ] Teste mit √§lteren Browser-Versionen
- [ ] Deaktiviere JavaScript
- [ ] Teste mit verschiedenen Bildschirmaufl√∂sungen
- [ ] Pr√ºfe mit eingeschr√§nkten Systemressourcen

**Erwartete Ergebnisse**:
- Graceful Degradation ohne JS
- Responsive Layout bei allen Aufl√∂sungen
- Keine Abst√ºrze bei Limits

### 3. Sicherheits-Tests

#### 3.1 Manipulationsversuche
**Ziel**: Serverseitige Validierung sicherstellen

**Tests**:
- [ ] Versuche, Spiel als Gast zu starten (DevTools)
- [ ] Manipuliere Spiel-Code in der URL
- [ ] Versuche, doppelte Namen zu verwenden
- [ ] Teste XSS-Versuche in Namensfeldern

**Erwartete Ergebnisse**:
- Server lehnt unauthorisierte Aktionen ab
- Keine M√∂glichkeit zur Manipulation des Spielstands
- Eingabe-Sanitierung funktioniert

#### 3.2 Privatsph√§re-Tests
**Ziel**: Sicherstellen, dass private Informationen gesch√ºtzt sind

**Tests**:
- [ ] Pr√ºfe, ob Rollen anderer Spieler sichtbar sind
- [ ] √úberpr√ºfe, ob W√∂rter durchsickern
- [ ] Teste, ob Chat/Logs sensitive Daten enthalten
- [ ] Kontrolliere localStorage auf sensitive Daten

**Erwartete Ergebnisse**:
- Rollen sind strikt privat
- Keine Informationslecks
- Sensitive Daten nicht persistiert

### 4. Performance-Tests

#### 4.1 Ladezeiten
**Ziel**: Schnelle Ladezeiten auch bei schlechten Verbindungen

**Tests**:
- [ ] Messung des ersten sinnvollen Paints
- [ ] Zeit bis zur Interaktivit√§t
- [ ] Ladezeit bei Cold Cache
- [ ] Performance bei vielen Spielern

**Erwartete Ergebnisse**:
- < 3 Sekunden bis zum vollst√§ndigen Laden
- Keine Blockierungen durch gro√üe Ressourcen
- Fl√ºssige Animationen bei 60fps

#### 4.2 Speichernutzung
**Ziel**: Effiziente Ressourcennutzung

**Tests**:
- [ ] √úberwache Speichernutzung w√§hrend des Spiels
- [ ] Teste Memory Leaks bei langen Sessions
- [ ] Pr√ºfe CPU-Auslastung w√§hrend Animationen

**Erwartete Ergebnisse**:
- Kein √ºberm√§√üiger Speicherverbrauch
- Stabile Performance √ºber Zeit
- Geringe CPU-Auslastung

### 5. Accessibility-Tests

#### 5.1 Screenreader-Kompatibilit√§t
**Ziel**: Barrierefreiheit f√ºr blinde/sehbehinderte Nutzer

**Tests**:
- [ ] Teste mit VoiceOver (iOS) und TalkBack (Android)
- [ ] √úberpr√ºfe ARIA-Labels und -Attribute
- [ ] Kontrolliere Tastaturnavigation
- [ ] Pr√ºfe Farbkontrast mit Kontrast-Tools

**Erwartete Ergebnisse**:
- Alle Elemente screenreader-freundlich
- Vollst√§ndige Tastatur-Navigation m√∂glich
- Farbkontrast ‚â• 4.5:1

#### 5.2 Motorische F√§higkeiten
**Ziel**: Bedienung f√ºr Menschen mit motorischen Einschr√§nkungen

**Tests**:
- [ ] Teste mit vergr√∂√üerten Systemeinstellungen
- [ ] √úberpr√ºfe Erreichbarkeit aller interaktiven Elemente
- [ ] Pr√ºfe Alternative Input-Methoden

**Erwartete Ergebnisse**:
- Skalierung funktioniert korrekt
- Gro√üe Touch-Ziele f√ºr alle Elemente
- Alternative Bedienung m√∂glich

## üìù Testprotokoll

### Durchf√ºhrung der Tests
1. **Vorbereitung**: √ñffne Test-Checkliste
2. **Durchf√ºhrung**: Gehe jeden Testpunkt durch
3. **Dokumentation**: Markiere Erfolge/Fehler
4. **Bewertung**: Schweregrad der Probleme einstufen
5. **Nachverfolgung**: Erstelle Tickets f√ºr gefundene Issues

### Schweregrad-Klassifikation
- **Blocker**: Verhindert Kernfunktionalit√§t
- **Critical**: Beeintr√§chtigt Nutzererfahrung stark
- **Major**: Funktioniert aber mit Einschr√§nkungen
- **Minor**: Kosmetische oder kleine UX-Probleme
- **Trivial**: Kaum bemerkbare Probleme

### Test-Dashboard
F√ºr jeden Test sollte dokumentiert werden:
- Ger√§t/Browser
- Datum/Uhrzeit
- Tester
- Ergebnis (‚úÖ/‚ùå)
- Probleme/Beobachtungen
- Screenshots/Videos bei Problemen
- Reproduktionsschritte

## üîç Explorative Test-Sessions

### Session 1: Neue User Experience
**Ziel**: Erfahrung eines v√∂llig neuen Nutzers simulieren
- [ ] Erste Nutzung ohne Anleitung
- [ ] Verstehen des Spielablaufs
- [ ] Intuitivit√§t der Bedienung
- [ ] Klarheit der Anweisungen

### Session 2: Power User Testing
**Ziel**: Erfahrene Nutzer unter Stressbedingungen testen
- [ ] Schnelle Navigation durch Screens
- [ ] Multitasking w√§hrend des Spiels
- [ ] Tastaturk√ºrzel und Shortcuts
- [ ] Effizienz der Workflows

### Session 3: Fehler-Handling
**Ziel**: Robustheit bei unerwarteten Situationen
- [ ] Absichtliche Fehleingaben
- [ ] Systematische Fehlerprovokation
- [ ] Grenzwert-Tests
- [ ] DDoC (Denial of Coffee) Tests

## üìä Ergebnisse und Metriken

### Zu messende Metriken
- **Task Success Rate**: % der erfolgreich abgeschlossenen Aufgaben
- **Time on Task**: Durchschnittliche Zeit pro Aufgabe
- **Error Rate**: H√§ufigkeit von Fehlern
- **Satisfaction Score**: Nutzerzufriedenheit
- **Accessibility Score**: WCAG-Konformit√§t

### Berichtsvorlage
```
Test Session: [Datum]
Tester: [Name]
Ger√§te: [Liste]
Ergebnisse:
- Erfolgreiche Tests: X/Y
- Kritische Fehler: X
- Verbesserungspotenzial: X/5

Top Issues:
1. [Beschreibung] - [Schweregrad]
2. [Beschreibung] - [Schweregrad]
3. [Beschreibung] - [Schweregrad]

Empfehlungen:
- [Immediate Actions]
- [Short-term Improvements]  
- [Long-term Strategy]
```

Diese explorativen Tests sollten regelm√§√üig durchgef√ºhrt werden, besonders vor neuen Releases, um kontinuierliche Qualit√§t sicherzustellen.